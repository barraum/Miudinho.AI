# app.py (vers√£o final unificada)
import streamlit as st
import google.generativeai as genai
import faiss
import pickle
import numpy as np
import json
from pytubefix import YouTube
import xml.etree.ElementTree as ET

# --- CONFIGURA√á√ÉO INICIAL DA P√ÅGINA ---
st.set_page_config(
    page_title="MiudinhoAI",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ MiudinhoAI - An√°lise e Busca de Conte√∫do")
st.caption("Uma interface para buscar em todo o acervo ou analisar v√≠deos individuais do canal Miudinho Uberaba.")

# --- SEGURAN√áA E CONFIGURA√á√ÉO DA API ---
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except (KeyError, FileNotFoundError):
    st.error("ERRO: A chave da API do Gemini n√£o foi encontrada.")
    st.info("Por favor, crie um arquivo .streamlit/secrets.toml e adicione sua chave: GEMINI_API_KEY = 'SUA_CHAVE_AQUI'")
    st.stop()

# --- MODELOS GEMINI (centralizado) ---
GENERATIVE_MODEL = genai.GenerativeModel('gemini-2.5-flash')
EMBEDDING_MODEL = 'models/text-embedding-004'

# --- ARQUIVOS E CONSTANTES (centralizado) ---
FAISS_INDEX_FILE = 'banco_vetorial_gemini_txt_900.index'
CHUNKS_MAPPING_FILE = 'chunks_mapeamento_gemini_txt_900.pkl'
VIDEO_JSON_FILE = 'videos_miudinho_uberaba.json'

# --- FUN√á√ïES AUXILIARES DA ABA DE BUSCA (RAG) ---

# @st.cache_resource √© ideal para carregar modelos, conex√µes ou dados pesados que n√£o mudam.
@st.cache_resource
def load_faiss_index():
    """Carrega o √≠ndice FAISS e os metadados do disco."""
    try:
        index = faiss.read_index(FAISS_INDEX_FILE)
        with open(CHUNKS_MAPPING_FILE, 'rb') as f:
            metadata = pickle.load(f)
        return index, metadata
    except FileNotFoundError:
        st.error(f"ERRO: Arquivos de banco de vetores ('{FAISS_INDEX_FILE}' ou '{CHUNKS_MAPPING_FILE}') n√£o encontrados!")
        st.warning("Verifique se os arquivos est√£o no reposit√≥rio e se o Git LFS foi usado corretamente.")
        return None, None

def buscar_chunks_relevantes(queries: list, index, metadata, k=10):
    """
    Busca os k chunks mais relevantes para uma LISTA de perguntas e retorna
    os metadados √∫nicos dos chunks encontrados.
    """
    # 1. Transforma a lista de perguntas em uma lista de vetores
    result = genai.embed_content(
        model=EMBEDDING_MODEL,
        content=queries,
        task_type="RETRIEVAL_QUERY"
    )
    query_vectors = np.array(result['embedding'])

    # 2. Busca no FAISS por todos os vetores de uma vez
    # O resultado 'indices' ser√° uma lista de listas (uma para cada pergunta)
    distances, indices = index.search(query_vectors, k)
    
    # 3. Junta todos os √≠ndices encontrados em um conjunto para remover duplicatas
    unique_indices = set()
    for indice_list in indices:
        for idx in indice_list:
            # -1 √© um valor que o FAISS pode retornar se n√£o encontrar vizinhos suficientes
            if idx != -1:
                unique_indices.add(idx)

    # 4. Retorna os metadados dos chunks √∫nicos encontrados
    return [metadata[idx] for idx in unique_indices]

def gerar_resposta_com_busca(query, chunks_relevantes):
    """Gera uma resposta com base na busca, incluindo cita√ß√µes."""
    contexto_formatado = "\n\n--- DOCUMENTOS RELEVANTES PARA CONSULTA ---\n"
    for chunk in chunks_relevantes:
        nome_arquivo_fonte = chunk['source_file']
        contexto_formatado += f"\nDOCUMENTO: {nome_arquivo_fonte}\n"
        contexto_formatado += f"CONTE√öDO:\n'''{chunk['text']}'''\n"
    contexto_formatado += "\n--- FIM DOS DOCUMENTOS RELEVANTES ---\n"

    prompt = f"""
    Voc√™ √© um assistente teol√≥gico especialista. Sua tarefa √© responder √† pergunta do usu√°rio de forma detalhada e estruturada, utilizando EXCLUSIVAMENTE os trechos de texto fornecidos.

    **Instru√ß√µes Cruciais:**
    1.  Sintetize uma resposta completa e coesa.
    2.  Ao final de CADA frase que utilize informa√ß√£o de um documento, voc√™ DEVE citar o nome do arquivo correspondente usando o formato `[nome do arquivo.txt]`.
    3.  Se o conte√∫do n√£o for suficiente, diga "Com base nos trechos fornecidos, n√£o tenho informa√ß√£o suficiente para responder a essa pergunta.".
    4.  N√£o crie uma se√ß√£o de "Refer√™ncias" no final. A cita√ß√£o deve estar no corpo do texto.

    **PERGUNTA DO USU√ÅRIO:**
    "{query}"

    **DOCUMENTOS PARA CONSULTA:**
    {contexto_formatado}

    Agora, construa sua resposta seguindo todas as instru√ß√µes.
    """
    try:
        response = GENERATIVE_MODEL.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"Ocorreu um erro ao gerar a resposta: {e}"

# --- FUN√á√ïES AUXILIARES DA ABA DE AN√ÅLISE DE V√çDEO ---

@st.cache_data
def load_video_data(filepath):
    """Carrega os dados dos v√≠deos a partir de um arquivo JSON."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"ERRO: O arquivo de dados '{filepath}' n√£o foi encontrado.")
        return None
    except json.JSONDecodeError:
        st.error(f"ERRO: O arquivo '{filepath}' n√£o √© um JSON v√°lido.")
        return None

def get_video_transcript(url):
    """
    Extrai a transcri√ß√£o de um v√≠deo do YouTube usando pytubefix para evitar bloqueios de IP.
    """
    try:
        yt = YouTube(url)
        
        # Prioriza a busca por legendas em portugu√™s: manual, brasileira, depois autom√°tica
        caption = None
        if 'pt' in yt.captions:
            caption = yt.captions['pt']
        elif 'pt-BR' in yt.captions:
            caption = yt.captions['pt-BR']
        elif 'a.pt' in yt.captions:
            caption = yt.captions['a.pt']
        
        # Se nenhuma legenda em portugu√™s for encontrada
        if not caption:
            st.error("ERRO: N√£o foi poss√≠vel encontrar legendas em portugu√™s (manuais ou autom√°ticas) para este v√≠deo.")
            st.warning("Verifique se o v√≠deo possui legendas em portugu√™s no YouTube.")
            return None

        # As legendas v√™m em formato XML, ent√£o precisamos process√°-las
        xml_captions = caption.xml_captions
        
        # Usa o ElementTree para extrair o texto de dentro das tags XML
        root = ET.fromstring(xml_captions)
        transcript_lines = []
        for elem in root.iter('text'):
            if elem.text:
                transcript_lines.append(elem.text)
        
        if not transcript_lines:
            st.error("ERRO: A trilha de legenda foi encontrada, mas est√° vazia.")
            return None

        return " ".join(transcript_lines)

    except Exception as e:
        st.error(f"Ocorreu um erro inesperado ao tentar buscar as legendas com pytubefix: {e}")
        st.info("Isso pode ser um problema com a biblioteca, a URL do v√≠deo ou uma restri√ß√£o de acesso.")
        return None
    
def expand_query_with_gemini(user_query):
    """
    Usa o Gemini para gerar varia√ß√µes de uma pergunta de forma robusta.
    Retorna uma lista de perguntas, incluindo a original.
    """
    try:
        # PROMPT SIMPLIFICADO: Pede uma lista separada por quebras de linha.
        prompt = f"""
        Voc√™ √© um assistente de busca especialista em teologia e estudos b√≠blicos.
        Gere 4 varia√ß√µes da pergunta do usu√°rio para melhorar a busca em uma base de dados de transcri√ß√µes de v√≠deos.
        Concentre-se em sin√¥nimos, conceitos relacionados e formas alternativas de expressar o mesmo significado.
        
        Pergunta Original: "{user_query}"

        Retorne APENAS as perguntas geradas. Liste cada pergunta em uma nova linha. N√ÉO use marcadores, n√∫meros ou qualquer outra formata√ß√£o.
        """
        
        response = GENERATIVE_MODEL.generate_content(prompt)
        
        # PARSING ROBUSTO: Divide a resposta por quebras de linha.
        # Usa uma list comprehension para limpar espa√ßos em branco e remover linhas vazias.
        expanded_queries = [line.strip() for line in response.text.strip().split('\n') if line.strip()]
        
        # Garante que a pergunta original esteja no in√≠cio da lista
        expanded_queries.insert(0, user_query)
            
        return expanded_queries
    
    except Exception as e:
        # Se qualquer coisa der errado, retorna a pergunta original em uma lista.
        print(f"Erro ao expandir a pergunta: {e}. Usando a pergunta original.")
        return [user_query]    

# --- INTERFACE PRINCIPAL COM ABAS ---
tab1, tab2 = st.tabs(["**üîç Busca em Todo o Acervo**", "**üé¨ An√°lise de V√≠deo Individual**"])

# --- ABA 1: BUSCA EM TODO O ACERVO ---
with tab1:
    st.header("Busque por temas em todos os estudos")
    st.info("Fa√ßa uma pergunta em linguagem natural e o MiudinhoAI buscar√° a resposta em todos os v√≠deos com legendas dispon√≠veis, citando as fontes.")

    # Carrega os dados para a busca
    index, metadata = load_faiss_index()

    if index is not None:
        user_query = st.text_input("Digite sua pergunta:", key="search_query")

        # No seu app.py, ajuste o valor de K aqui. Comece com 10 ou 15.
        K_VALUE = 15 

        if st.button("Buscar Resposta", type="primary", use_container_width=True):
            if user_query:
                # 1. Expande a pergunta
                with st.spinner("Refinando e expandindo a pergunta..."):
                    expanded_queries = expand_query_with_gemini(user_query)

                # (Opcional, mas √≥timo para depura√ß√£o) Mostra as perguntas usadas
                with st.expander("Ver varia√ß√µes de busca utilizadas"):
                    st.write(expanded_queries)

                # 2. Busca usando a lista de perguntas
                with st.spinner("Buscando trechos relevantes no acervo..."):
                    chunks_relevantes = buscar_chunks_relevantes(expanded_queries, index, metadata, k=K_VALUE)
                
                if not chunks_relevantes:
                    st.warning("N√£o foram encontrados trechos relevantes para a sua pergunta.")
                else:
                    # O resto do c√≥digo permanece igual
                    with st.spinner("O MiudinhoAI est√° sintetizando a resposta... üß†‚úçÔ∏è"):
                        resposta_final = gerar_resposta_com_busca(user_query, chunks_relevantes)
                    
                    st.subheader("Resposta Gerada")
                    st.markdown(resposta_final)

                    # NOVO: Adiciona um expansor para mostrar os chunks de contexto
                    with st.expander("üìö Ver os trechos exatos enviados ao Gemini como contexto"):
                        st.markdown("A resposta acima foi gerada com base nos seguintes trechos de texto recuperados do seu acervo:")
                        
                        # Itera sobre cada chunk relevante e o exibe de forma organizada
                        for i, chunk in enumerate(chunks_relevantes):
                            st.markdown("---") # Adiciona uma linha divis√≥ria
                            
                            # Mostra a origem do chunk
                            st.markdown(f"**Chunk {i+1} | Fonte:** `{chunk['source_file']}`")
                            
                            # Usa st.info para dar um destaque visual ao texto do chunk
                            st.info(chunk['text'])

            else:
                st.warning("Por favor, digite uma pergunta.")

# --- ABA 2: AN√ÅLISE DE V√çDEO INDIVIDUAL (VERS√ÉO CORRIGIDA E COMPLETA) ---
with tab2:
    st.header("Analise um v√≠deo espec√≠fico")
    st.info("Escolha um v√≠deo da lista para obter um resumo inteligente ou uma an√°lise de express√µes e refer√™ncias.")

    # Carrega os dados dos v√≠deos para esta aba
    video_data = load_video_data(VIDEO_JSON_FILE)

    if video_data:
        video_titles = [video['titulo'] for video in video_data]
        selected_title = st.selectbox("Escolha um dos v√≠deos para analisar:", options=video_titles, key="video_selector")
        
        # Encontra o dicion√°rio completo do v√≠deo selecionado
        selected_video = next((video for video in video_data if video['titulo'] == selected_title), None)

        if selected_video:
            col1, col2 = st.columns([1, 2])
            with col1:
                st.video(selected_video['url'])
            with col2:
                st.subheader("Informa√ß√µes do V√≠deo")
                st.write(f"**T√≠tulo:** {selected_video['titulo']}")
                # Garante que a descri√ß√£o (vers√≠culo) existe e n√£o est√° vazia antes de mostrar
                if 'descricao' in selected_video and selected_video['descricao']:
                    st.write(f"**üìú Vers√≠culo-chave:** *{selected_video['descricao']}*")
            
            st.divider()

            action = st.radio(
                "O que voc√™ gostaria de fazer com este v√≠deo?",
                ("An√°lise de Express√µes e Refer√™ncias", "Resumo Inteligente do V√≠deo"),
                key="action_choice",
                horizontal=True
            )

            if st.button("Analisar com Gemini", key="analyze_button", use_container_width=True):
                with st.spinner("Buscando legendas do v√≠deo... üìú"):
                    transcript = get_video_transcript(selected_video['url'])

                # A M√ÅGICA ACONTECE AQUI:
                # Toda a l√≥gica a seguir s√≥ √© executada SE a transcri√ß√£o for obtida com sucesso.
                if transcript:
                    prompt_base = ""
                    generation_config = genai.types.GenerationConfig(
                        temperature=0.2 
                    )

                    # 1. Define o prompt base de acordo com a a√ß√£o escolhida
                    if action == "An√°lise de Express√µes e Refer√™ncias":
                        prompt_base = f"""
                        Voc√™ √© um assistente de pesquisa acad√™mica especializado em estudos b√≠blicos com base na Doutrina Esp√≠rita.
                        Sua tarefa √© analisar a transcri√ß√£o de um v√≠deo e o vers√≠culo-chave fornecidos para extrair informa√ß√µes espec√≠ficas.
                        FORMATE SUA RESPOSTA USANDO MARKDOWN.
                        Com base em AMBOS (a transcri√ß√£o e o vers√≠culo), extraia e liste APENAS o seguinte:
                        
                        ### Palavras e Express√µes em An√°lise
                        Liste a(s) palavra(s) ou express√£o(√µes) do vers√≠culo que s√£o o foco principal da an√°lise no v√≠deo. Geralmente, o palestrante menciona explicitamente qual termo est√° "estudando miudinho".

                        ### Refer√™ncias Bibliogr√°ficas
                        Liste todos os livros, autores e cap√≠tulos que s√£o explicitamente mencionados no v√≠deo como fonte de consulta. Use o formato: `Livro (Autor) - Cap√≠tulo/Refer√™ncia`.
                        Se nenhuma refer√™ncia bibliogr√°fica for mencionada, escreva "Nenhuma refer√™ncia bibliogr√°fica expl√≠cita foi mencionada.".
                        N√£o adicione conclus√µes ou qualquer outra informa√ß√£o al√©m do que foi solicitado.
                        """
                    
                    elif action == "Resumo Inteligente do V√≠deo":
                        prompt_base = f"""
                        Voc√™ √© um especialista em s√≠ntese de conte√∫do. Sua tarefa √© criar um resumo claro e informativo que conecte a transcri√ß√£o de um v√≠deo ao seu vers√≠culo-chave.
                        FORMATE SUA RESPOSTA USANDO MARKDOWN.
                        Siga estas instru√ß√µes:
                        
                        ### Resumo da An√°lise
                        Em 2 a 3 par√°grafos, explique como a prega√ß√£o no v√≠deo aprofunda e interpreta o tema central apresentado no vers√≠culo-chave. O resumo deve ser conciso e fiel ao conte√∫do.

                        ### T√≥picos Principais
                        Liste de 3 a 5 pontos ou argumentos centrais apresentados no v√≠deo que explicam o vers√≠culo.
                        """

                    # 2. Constr√≥i o prompt final com todo o contexto
                    versiculo = selected_video.get('descricao', 'Nenhum vers√≠culo fornecido.')
                    
                    prompt_final = f"""
                    {prompt_base}

                    --- CONTEXTO PARA AN√ÅLISE ---
                    **VERS√çCULO-CHAVE:**
                    {versiculo}

                    **TRANSCRI√á√ÉO COMPLETA DO V√çDEO:**
                    {transcript}
                    """
                    
                    # 3. Chama a API e mostra o resultado
                    with st.spinner("O MiudinhoAI est√° analisando o conte√∫do... üß†‚úçÔ∏è"):
                        try:
                            response = GENERATIVE_MODEL.generate_content(
                                prompt_final,
                                generation_config=generation_config
                            )
                            st.header("Resultado da An√°lise")
                            st.markdown(response.text)

                        except Exception as e:
                            st.error(f"Ocorreu um erro ao chamar a API do Gemini: {e}")
                            st.info("Isso pode ocorrer por diversos motivos, como conte√∫do bloqueado por pol√≠ticas de seguran√ßa ou um problema tempor√°rio na API.")